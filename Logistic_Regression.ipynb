{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T22:01:55.744723Z",
     "start_time": "2020-01-02T22:01:55.739736Z"
    }
   },
   "source": [
    "<h2>Part 0: Introduction </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T15:21:23.603234Z",
     "start_time": "2020-01-02T15:21:23.588276Z"
    }
   },
   "source": [
    "In this tutorial, you will learn how to build a neural network for image classification using Logistic Regression from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T15:00:31.708237Z",
     "start_time": "2020-01-03T15:00:31.436817Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import re\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T13:13:30.737946Z",
     "start_time": "2020-01-03T13:13:30.733924Z"
    }
   },
   "source": [
    "<h3> Part 1 Goal </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T13:20:17.282229Z",
     "start_time": "2020-01-03T13:20:17.276245Z"
    }
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<img src=\"images/image2vector_kiank.png\",width=500,height=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T13:13:30.737946Z",
     "start_time": "2020-01-03T13:13:30.733924Z"
    }
   },
   "source": [
    "<h3> Part 2 Goal </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T13:20:17.290207Z",
     "start_time": "2020-01-03T13:20:17.283226Z"
    }
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<img src=\"images/LogReg_kiank.png\",width=500,height=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T20:05:47.363718Z",
     "start_time": "2020-01-02T20:05:47.358732Z"
    }
   },
   "source": [
    "<h2> Part 1: Data Preprocess </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a folder with the following folders.\n",
    "<br>\n",
    "<br>\n",
    "birds: contains images of the birds\n",
    "<br>\n",
    "other_images: contains a mix of random images\n",
    "<br>\n",
    "train_set: contains the images that will be used for training\n",
    "<br>\n",
    "test_set: contains the images that will be used to test the training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T21:43:22.379959Z",
     "start_time": "2020-01-02T21:43:22.374958Z"
    }
   },
   "source": [
    "<p> Objective <p>\n",
    "<li> Load the Dataset </li>\n",
    "<li> Visualize the Dataset </li>\n",
    "<li> Get a general understanding of the dataset </li>\n",
    "<li> Flatten and Reshape </li>\n",
    "<li> Standarize the Data </li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T15:21:23.603234Z",
     "start_time": "2020-01-02T15:21:23.588276Z"
    }
   },
   "source": [
    "<p> Step 1: Load the Dataset <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T13:20:17.295195Z",
     "start_time": "2020-01-03T13:20:17.291206Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def renamed_files(path, label):\n",
    "    \"\"\"\n",
    "    Rename files so they can contain \"bird\", this will be used to create the labels\n",
    "\n",
    "    Arguments:\n",
    "    path -- path where images are located that will be renamed\n",
    "    label -- the label the images will be get\n",
    "\n",
    "    Output:\n",
    "    files will be renamed in the same folder\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "\n",
    "    for filename in os.listdir(path):\n",
    "        try:\n",
    "            f, extension = os.path.splitext(path+filename)\n",
    "            src = path+filename\n",
    "            dst = path+label+str(i)+extension\n",
    "            os.rename(src, dst)\n",
    "            i += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            i += 1\n",
    "\n",
    "\n",
    "path = \"C://Users//Maged Helmy//Desktop//youTube//data_1//Test_Set//\"\n",
    "label = \"bird\"\n",
    "\n",
    "renamed_files(path, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T13:20:17.301178Z",
     "start_time": "2020-01-03T13:20:17.296191Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def resize_images(src_path, dst_path):\n",
    "    \"\"\"\n",
    "    # Resize images to 64 by 64 to speed up training process\n",
    "\n",
    "\n",
    "    Arguments:\n",
    "    src_path -- path where images are located that will be resized\n",
    "    dst_path -- new path where images are reized will be resized\n",
    "\n",
    "    Output:\n",
    "    images will be resized and save to dst_path provided    \n",
    "    \"\"\"\n",
    "\n",
    "    for filename in os.listdir(src_path):\n",
    "\n",
    "        try:\n",
    "            img = Image.open(src_path+filename)\n",
    "            new_img = img.resize((64, 64))\n",
    "            \n",
    "            if not os.path.exists(dst_path):\n",
    "                os.makedirs(dst_path)\n",
    "\n",
    "            new_img.save(dst_path+filename)\n",
    "            print('Resized and saved {} successfully.'.format(filename))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "\n",
    "src_path = \"C://Users//Maged Helmy//Desktop//youTube//data_1//birds//\"\n",
    "dst_path = \"C://Users//Maged Helmy//Desktop//youTube//data_1//training_set//\"\n",
    "\n",
    "resize_images(src_path, dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T15:00:40.201269Z",
     "start_time": "2020-01-03T15:00:40.051700Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_data(path):\n",
    "    \"\"\"\n",
    "    # Resize images to 64 by 64 to speed up training process\n",
    "\n",
    "\n",
    "    Arguments:\n",
    "    path -- path to where data is stored\n",
    "\n",
    "    Output:\n",
    "    np.array(all_images_as_array): Images converted to an array\n",
    "    np.array(label).reshape(1,-1): Labels extracted from images\n",
    "    \"\"\"\n",
    "\n",
    "    all_images_as_array = []\n",
    "    label = []\n",
    "\n",
    "    for filename in os.listdir(path):\n",
    "        try:\n",
    "            if re.match(r'bird', filename):\n",
    "                label.append(1)\n",
    "            else:\n",
    "                label.append(0)\n",
    "\n",
    "            img = Image.open(path + filename)\n",
    "            np_array = np.asarray(img)\n",
    "            #l, b, c = np_array.shape\n",
    "            #np_array = np_array.reshape(l*b*c,)\n",
    "            all_images_as_array.append(np_array)\n",
    "        except:\n",
    "            continue\n",
    "    return np.array(all_images_as_array), np.array(label).reshape(1, -1)\n",
    "\n",
    "\n",
    "path_to_train_set = \"C://Users//Maged Helmy//Desktop//youTube//data_1//train_set//\"\n",
    "path_to_test_set = \"C://Users//Maged Helmy//Desktop//youTube//data_1//test_set//\"\n",
    "\n",
    "train_set_x_orig, train_set_y = get_data(path_to_train_set)\n",
    "test_set_x_orig, test_set_y = get_data(path_to_test_set)\n",
    "\n",
    "print('X_train set : ', train_set_x_orig)\n",
    "print('y_train set : ', train_set_y)\n",
    "print('X_test set : ', test_set_x_orig)\n",
    "print('y_test set : ', test_set_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Step 1.1: Create Classes <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T15:00:40.208250Z",
     "start_time": "2020-01-03T15:00:40.202300Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create classes for your data\n",
    "list_classes = ['non-bird','bird']\n",
    "classes = np.array(list_classes) \n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T21:39:00.628396Z",
     "start_time": "2020-01-02T21:39:00.623409Z"
    }
   },
   "source": [
    "<p> Step 2: Visualize the Dataset <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T15:00:40.325966Z",
     "start_time": "2020-01-03T15:00:40.209247Z"
    }
   },
   "outputs": [],
   "source": [
    "# Example of a picture\n",
    "index = 350\n",
    "\n",
    "plt.imshow(train_set_x_orig[index])\n",
    "print (\"y = \" + str(train_set_y[:, index]) + \", it's a '\" + classes[np.squeeze(train_set_y[:, index])] +  \"' picture.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T15:21:23.603234Z",
     "start_time": "2020-01-02T15:21:23.588276Z"
    }
   },
   "source": [
    "<p> Step 3: Get a general feeling of the dataset <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T15:00:40.332944Z",
     "start_time": "2020-01-03T15:00:40.326933Z"
    }
   },
   "outputs": [],
   "source": [
    "m_train = train_set_x_orig.shape[0]\n",
    "m_test = test_set_x_orig.shape[0]\n",
    "num_px = train_set_x_orig.shape[1]\n",
    "\n",
    "print (\"Number of training examples: m_train = \" + str(m_train))\n",
    "print (\"Number of testing examples: m_test = \" + str(m_test))\n",
    "print (\"Height/Width of each image: num_px = \" + str(num_px))\n",
    "print (\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\n",
    "print (\"train_set_x shape: \" + str(train_set_x_orig.shape))\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_x shape: \" + str(test_set_x_orig.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T20:01:01.724609Z",
     "start_time": "2020-01-02T20:01:01.719618Z"
    }
   },
   "source": [
    "<p> Step 4: Flatten and Reshape the Dataset for Convenience of Representation<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T15:00:40.338900Z",
     "start_time": "2020-01-03T15:00:40.333913Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reshape the training and test examples\n",
    "\n",
    "train_set_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0], -1).T\n",
    "test_set_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0], -1).T\n",
    "\n",
    "print (\"train_set_x_flatten shape: \" + str(train_set_x_flatten.shape))\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_x_flatten shape: \" + str(test_set_x_flatten.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T20:01:33.695895Z",
     "start_time": "2020-01-02T20:01:33.691905Z"
    }
   },
   "source": [
    "<p> Step 5: Standarize the Dataset <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T15:00:40.366860Z",
     "start_time": "2020-01-03T15:00:40.339898Z"
    }
   },
   "outputs": [],
   "source": [
    "train_set_x = train_set_x_flatten/255.\n",
    "test_set_x = test_set_x_flatten/255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Part 2.0: Recap Neural Architecture </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T21:43:22.379959Z",
     "start_time": "2020-01-02T21:43:22.374958Z"
    }
   },
   "source": [
    "<p> Objective <p>\n",
    "<li> Write a sigmoid function </li>\n",
    "<li> Write a function to initlize logistic regression parameters w and b with zero</li>\n",
    "<li> Write a function that implements forward, backward and learning rate </li>\n",
    "<li> Write a function to predict, maybe merge with above ? </li>\n",
    "<li> Merge all above functions in a single function called model </li>\n",
    "<li> Adjust Learning Rates </li>    \n",
    "<li> Visualize Learning Rates </li>    \n",
    "<li> Add your own image </li>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T20:06:09.128021Z",
     "start_time": "2020-01-02T20:06:09.123034Z"
    }
   },
   "source": [
    "<h2> Part 2.1: Recap Logistic Regression </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mathematical expression of the algorithm**:\n",
    "\n",
    "For one example $x^{(i)}$:\n",
    "$$z^{(i)} = w^T x^{(i)} + b \\tag{1}$$\n",
    "$$\\hat{y}^{(i)} = a^{(i)} = sigmoid(z^{(i)}) = \\frac{1}{1 + e^{-(z)}} \\tag{2}$$\n",
    "$$ \\mathcal{L}(a^{(i)}, y^{(i)}) =  - y^{(i)}  \\log(a^{(i)}) - (1-y^{(i)} )  \\log(1-a^{(i)})\\tag{3}$$\n",
    "\n",
    "The cost is then computed by summing over all training examples:\n",
    "$$ J = \\frac{1}{m} \\sum_{i=1}^m \\mathcal{L}(a^{(i)}, y^{(i)})\\tag{6}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Part 2.2: Sigmoid Function </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T15:00:40.370815Z",
     "start_time": "2020-01-03T15:00:40.367822Z"
    }
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: sigmoid\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid of z\n",
    "\n",
    "    Arguments:\n",
    "    z -- A scalar or numpy array of any size.\n",
    "\n",
    "    Return:\n",
    "    s -- sigmoid(z)\n",
    "    \"\"\"\n",
    "    \n",
    "    s = 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Part 2.3: Intialize Values with Zero Function </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T15:00:40.377800Z",
     "start_time": "2020-01-03T15:00:40.372812Z"
    }
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: initialize_with_zeros\n",
    "\n",
    "def initialize_with_zeros(dim):\n",
    "    \"\"\"\n",
    "    This function creates a vector of zeros of shape (dim, 1) for w and initializes b to 0.\n",
    "    \n",
    "    Argument:\n",
    "    dim -- size of the w vector we want (or number of parameters in this case)\n",
    "    \n",
    "    Returns:\n",
    "    w -- initialized vector of shape (dim, 1)\n",
    "    b -- initialized scalar (corresponds to the bias)\n",
    "    \"\"\"\n",
    "    w = np.zeros((dim,1))\n",
    "    b = 0\n",
    "    \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T20:21:06.503675Z",
     "start_time": "2020-01-02T20:21:06.499685Z"
    }
   },
   "source": [
    "<h2> Part 2.4: Implement Forward  Propogation, Backward  Propogation, Iteration and Learning Rate </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T15:00:40.386804Z",
     "start_time": "2020-01-03T15:00:40.378793Z"
    }
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: optimize\n",
    "\n",
    "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost):\n",
    "    \"\"\"\n",
    "    This function optimizes w and b by running a gradient descent algorithm\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of shape (num_px * num_px * 3, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat), of shape (1, number of examples)\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    print_cost -- True to print the loss every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    params -- dictionary containing the weights w and bias b\n",
    "    grads -- dictionary containing the gradients of the weights and bias with respect to the cost function\n",
    "    costs -- list of all the costs computed during the optimization, this will be used to plot the learning curve.\n",
    "    \n",
    "    Tips:\n",
    "    You basically need to write down two steps and iterate through them:\n",
    "        1) Calculate the cost and the gradient for the current parameters. Use propagate().\n",
    "        2) Update the parameters using gradient descent rule for w and b.\n",
    "    \"\"\"\n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        \n",
    "        # Get the amount of training set\n",
    "        m = X.shape[1]\n",
    "\n",
    "        # FORWARD PROPAGATION (FROM X TO COST)\n",
    "        A = sigmoid(np.dot(w.T,X)+b)                                  # compute activation\n",
    "        cost = (-1/m)* np.sum((Y*np.log(A)) + (1-Y)*np.log(1-A))      # compute cost\n",
    "        cost = np.squeeze(cost)\n",
    "\n",
    "\n",
    "        # BACKWARD PROPAGATION (TO FIND GRAD)\n",
    "        dw = (np.dot(X, np.subtract(A,Y).T)) / m\n",
    "        db = (np.sum(A-Y)) / m\n",
    "\n",
    "        grads = {\"dw\": dw,\n",
    "                 \"db\": db}\n",
    "        \n",
    "        # Retrieve derivatives from grads\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        # update rule\n",
    "        w = w - learning_rate*dw\n",
    "        b = b - learning_rate*db\n",
    "        \n",
    "        # Record the costs\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "        \n",
    "        # Print the cost every 100 training iterations\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    \n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Part 2.7: Implement Predict  </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T15:00:40.393753Z",
     "start_time": "2020-01-03T15:00:40.387769Z"
    }
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: predict\n",
    "\n",
    "def predict(w, b, X):\n",
    "    '''\n",
    "    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (num_px * num_px * 3, number of examples)\n",
    "    \n",
    "    Returns:\n",
    "    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n",
    "    '''\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1,m))\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "    \n",
    "    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n",
    "    A = sigmoid(np.dot(w.T,X)+b)\n",
    "    \n",
    "    for i in range(A.shape[1]):\n",
    "        \n",
    "        # Convert probabilities A[0,i] to actual predictions p[0,i]\n",
    "        Y_prediction[0,i] = 0 if A[0,i] <= 0.5 else 1\n",
    "    \n",
    "    \n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Part 2.8: The Model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T15:01:22.143263Z",
     "start_time": "2020-01-03T15:01:15.300607Z"
    }
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: model\n",
    "\n",
    "def model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False):\n",
    "    \"\"\"\n",
    "    Builds the logistic regression model by calling the function you've implemented previously\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set represented by a numpy array of shape (num_px * num_px * 3, m_train)\n",
    "    Y_train -- training labels represented by a numpy array (vector) of shape (1, m_train)\n",
    "    X_test -- test set represented by a numpy array of shape (num_px * num_px * 3, m_test)\n",
    "    Y_test -- test labels represented by a numpy array (vector) of shape (1, m_test)\n",
    "    num_iterations -- hyperparameter representing the number of iterations to optimize the parameters\n",
    "    learning_rate -- hyperparameter representing the learning rate used in the update rule of optimize()\n",
    "    print_cost -- Set to true to print the cost every 100 iterations\n",
    "    \n",
    "    Returns:\n",
    "    d -- dictionary containing information about the model.\n",
    "    \"\"\"\n",
    "        \n",
    "    # initialize parameters with zeros \n",
    "    w, b = initialize_with_zeros(X_train.shape[0])\n",
    "\n",
    "    # Gradient descent \n",
    "    parameters, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost)\n",
    "    \n",
    "    # Retrieve parameters w and b from dictionary \"parameters\"\n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "    \n",
    "    # Predict test/train set examples (≈ 2 lines of code)\n",
    "    Y_prediction_test = predict(w, b, X_test)\n",
    "    Y_prediction_train = predict(w, b, X_train)\n",
    "\n",
    "    # Print train/test Errors\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "\n",
    "    \n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": Y_prediction_test, \n",
    "         \"Y_prediction_train\" : Y_prediction_train, \n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    \n",
    "    return d\n",
    "\n",
    "d = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 2000, learning_rate = 0.005, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T13:20:23.961354Z",
     "start_time": "2020-01-03T13:20:17.714073Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T15:00:47.418954Z",
     "start_time": "2020-01-03T15:00:47.274338Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot learning curve (with costs)\n",
    "costs = np.squeeze(d['costs'])\n",
    "plt.plot(costs)\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per hundreds)')\n",
    "plt.title(\"Learning rate =\" + str(d[\"learning_rate\"]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Part 2.9: Adjusting Learning Rates</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T15:01:01.846341Z",
     "start_time": "2020-01-03T15:00:47.420947Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "models = {}\n",
    "for i in learning_rates:\n",
    "    print (\"learning rate is: \" + str(i))\n",
    "    models[str(i)] = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 1500, learning_rate = i, print_cost = False)\n",
    "    print ('\\n' + \"-------------------------------------------------------\" + '\\n')\n",
    "\n",
    "for i in learning_rates:\n",
    "    plt.plot(np.squeeze(models[str(i)][\"costs\"]), label= str(models[str(i)][\"learning_rate\"]))\n",
    "\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (hundreds)')\n",
    "\n",
    "legend = plt.legend(loc='upper center', shadow=True)\n",
    "frame = legend.get_frame()\n",
    "frame.set_facecolor('0.90')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Part 2.10: Adding your own Image</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T15:01:02.018877Z",
     "start_time": "2020-01-03T15:01:01.847338Z"
    }
   },
   "outputs": [],
   "source": [
    "# We preprocess the image to fit your algorithm.\n",
    "\n",
    "img = Image.open(\"C://Users//Maged Helmy//Desktop//youTube//data_1//archive//images//027.Shiny_Cowbird//Shiny_Cowbird_0001_480522861.jpg\")\n",
    "new_img = img.resize((64, 64))\n",
    "np_array = np.asarray(new_img)\n",
    "\n",
    "my_image_flatten = np_array/255.\n",
    "my_image = my_image_flatten.reshape(1, -1).T\n",
    "\n",
    "my_predicted_image = predict(d[\"w\"], d[\"b\"], my_image)\n",
    "\n",
    "plt.imshow(my_image_flatten)\n",
    "print(\"y = \" + str(np.squeeze(my_predicted_image)) + \", your algorithm predicts a \\\"\" + classes[int(np.squeeze(my_predicted_image)),] +  \"\\\" picture.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
